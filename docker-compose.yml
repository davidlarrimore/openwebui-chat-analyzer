services:
  openwebui-chat-analyzer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: openwebui-chat-analyzer
    ports:
      - "8501:8501"
    volumes:
      # Optional: Mount local data directory for persistent storage
      - ./data:/app/data:rw
      # Optional: Mount uploads directory 
      - ./uploads:/app/uploads:rw
    environment:
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
      - STREAMLIT_SERVER_FILE_WATCHER_TYPE=none
      - MPLCONFIGDIR=/tmp/matplotlib
      # Optional: Set timezone
      - TZ=UTC
    restart: unless-stopped
    # Resource limits (adjust based on your needs)
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Security options
    security_opt:
      - no-new-privileges:true
    # Read-only root filesystem (except for necessary writable directories)
    read_only: true
    tmpfs:
      - /tmp:rw,noexec,nosuid,size=512m
      - /var/tmp:rw,noexec,nosuid,size=512m

  # Optional: Add a reverse proxy for production deployment
  nginx:
    image: nginx:alpine
    container_name: openwebui-chat-analyzer-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - openwebui-chat-analyzer
    restart: unless-stopped
    profiles:
      - production