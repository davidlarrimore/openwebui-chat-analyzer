"""Pydantic models for the Open WebUI Chat Analyzer backend."""

from datetime import date, datetime
from typing import Any, Dict, List, Optional, Literal

from pydantic import BaseModel, Field, model_validator


class Chat(BaseModel):
    """Serialized chat metadata as exposed by the API.

    Attributes:
        chat_id: Unique identifier for the chat conversation.
        user_id: Owning user identifier, if available.
        title: User-facing conversation title.
        gen_chat_summary: Locally generated summary string.
        gen_chat_outcome: Conversation outcome score (1-5).
        created_at: Creation timestamp pulled from the export.
        updated_at: Last modification timestamp pulled from the export.
        timestamp: Primary Open WebUI timestamp for the chat, when present.
        archived: Whether the chat is marked archived.
        pinned: Whether the chat is pinned in the source system.
        tags: Optional tags carried over from the export metadata.
        files_uploaded: Number of files attached to the chat.
        files: Opaque metadata about uploaded files, if any.
        meta: Raw metadata dictionary provided by the export.
        models: Recorded model identifiers for the chat.
        params: Conversation parameter overrides recorded in the export.
        share_id: Shared link identifier from the source system.
        folder_id: Folder grouping identifier if the chat was organized.
        history_current_id: Identifier of the currently active history node.
    """

    chat_id: str = Field(..., description="Unique identifier for the chat")
    user_id: Optional[str] = Field(
        default=None, description="Identifier for the user that owns the chat"
    )
    title: Optional[str] = Field(default=None, description="Chat title")
    gen_chat_summary: Optional[str] = Field(
        default=None,
        description="Conversation summary generated by the analyzer",
    )
    gen_chat_outcome: Optional[int] = Field(
        default=None,
        ge=1,
        le=5,
        description="Conversation outcome score (1=Not Successful, 5=Fully Successful)",
    )
    created_at: Optional[datetime] = Field(
        default=None, description="Timestamp when the chat was created"
    )
    updated_at: Optional[datetime] = Field(
        default=None, description="Timestamp when the chat was last updated"
    )
    timestamp: Optional[datetime] = Field(
        default=None, description="Primary Open WebUI timestamp associated with the chat"
    )
    archived: bool = Field(default=False, description="Whether the chat is archived")
    pinned: bool = Field(default=False, description="Whether the chat is pinned")
    tags: List[str] = Field(default_factory=list, description="Tags associated with chat")
    files_uploaded: int = Field(
        default=0, description="Number of files uploaded alongside the chat"
    )
    files: List[Any] = Field(
        default_factory=list,
        description="Raw file metadata from the chat export, if present",
    )
    meta: Dict[str, Any] = Field(
        default_factory=dict,
        description="Raw metadata dictionary emitted by the Open WebUI export",
    )
    models: List[str] = Field(
        default_factory=list,
        description="Models recorded by the export as having participated in the chat",
    )
    params: Dict[str, Any] = Field(
        default_factory=dict,
        description="Conversation parameter overrides included in the export payload",
    )
    share_id: Optional[str] = Field(
        default=None,
        description="Shared link identifier associated with the chat, if any",
    )
    folder_id: Optional[str] = Field(
        default=None,
        description="Folder grouping identifier assigned within Open WebUI",
    )
    history_current_id: Optional[str] = Field(
        default=None,
        description="Identifier of the currently selected history branch from the export",
    )

class Message(BaseModel):
    """Serialized chat message used in analytics and summarization.

    Attributes:
        chat_id: Identifier for the parent chat.
        message_id: Stable identifier for the message.
        parent_id: Identifier of the parent message, used for threading.
        role: Role of sender (user/assistant).
        content: Plain-text message content.
        timestamp: Source timestamp from the export, if provided.
        model: Name of the model that produced the response (if assistant).
        models: Alternate model names when the export contains multiple values.
        children_ids: Identifiers of direct child messages in the conversation tree.
        follow_ups: Suggested follow-up prompts surfaced by Open WebUI.
        status_history: Step-by-step LLM tool/action trace for the message.
        sources: Retrieval sources or citations associated with the message.
        files: Files directly attached to the message.
        annotation: Structured annotation payload (if the message was reviewed).
        model_name: Human-friendly model display name from the export.
        model_index: Numeric model index recorded by the export.
        last_sentence: Final sentence recorded by the export for assistant messages.
        done: Flag indicating whether the assistant marked the response complete.
        favorite: Flag indicating whether the message was favorited.
        feedback_id: Identifier of any feedback entry tied to the message.
        error: Error payload when the source LLM invocation failed.
    """

    chat_id: str = Field(..., description="Identifier of the chat this message belongs to")
    message_id: str = Field(..., description="Unique identifier for the message")
    parent_id: Optional[str] = Field(
        default=None, description="Identifier of the parent message if present"
    )
    role: str = Field(..., description="Role of the sender (user or assistant)")
    content: str = Field(..., description="Message content as plain text")
    timestamp: Optional[datetime] = Field(
        default=None, description="Timestamp when the message was created"
    )
    model: str = Field(default="", description="Model name associated with the message")
    models: List[str] = Field(
        default_factory=list, description="List of alternative model names, if any"
    )
    children_ids: List[str] = Field(
        default_factory=list, description="Identifiers for messages that reply to this one"
    )
    follow_ups: List[str] = Field(
        default_factory=list, description="Suggested follow-up prompts captured in the export"
    )
    status_history: List[Dict[str, Any]] = Field(
        default_factory=list, description="LLM status trace entries for this message"
    )
    sources: List[Dict[str, Any]] = Field(
        default_factory=list, description="Retrieval source metadata attached to the message"
    )
    files: List[Dict[str, Any]] = Field(
        default_factory=list, description="Files attached directly to the message"
    )
    annotation: Optional[Dict[str, Any]] = Field(
        default=None, description="Structured annotation metadata for the message"
    )
    model_name: Optional[str] = Field(
        default=None, description="Display name for the model recorded by the export"
    )
    model_index: Optional[int] = Field(
        default=None, description="Index of the model within the export payload"
    )
    last_sentence: Optional[str] = Field(
        default=None,
        description="Last sentence extracted by the export for assistant responses",
    )
    done: Optional[bool] = Field(
        default=None, description="Whether Open WebUI marked the assistant reply as complete"
    )
    favorite: Optional[bool] = Field(
        default=None, description="Whether the message was favorited in Open WebUI"
    )
    feedback_id: Optional[str] = Field(
        default=None, description="Identifier of any feedback item linked to the message"
    )
    error: Optional[Dict[str, Any]] = Field(
        default=None, description="Error metadata when the message generation failed"
    )


class ModelInfo(BaseModel):
    """Metadata describing an Open WebUI model."""

    model_id: str = Field(..., description="Unique identifier for the model as reported by Open WebUI")
    name: Optional[str] = Field(default=None, description="Human-friendly model display name")
    owned_by: Optional[str] = Field(default=None, description="Owning provider or namespace")
    connection_type: Optional[str] = Field(
        default=None, description="Connection type for the model (e.g. internal, external)"
    )
    object: Optional[str] = Field(default=None, description="Object type reported by the API")
    raw: Dict[str, Any] = Field(
        default_factory=dict, description="Original payload returned by the Open WebUI API for this model"
    )


class User(BaseModel):
    """Serialized user metadata consumed by the frontend."""

    user_id: str = Field(..., description="Unique user identifier")
    name: str = Field(..., description="Display name")


class AppMetadata(BaseModel):
    """High-level metadata about the current application dataset."""

    dataset_source: str = Field(..., description="Origin of the current dataset")
    dataset_pulled_at: Optional[datetime] = Field(
        default=None,
        description="UTC timestamp when the dataset was retrieved from its source",
    )
    chat_uploaded_at: Optional[datetime] = Field(
        default=None,
        description="UTC timestamp when chat data was most recently ingested",
    )
    users_uploaded_at: Optional[datetime] = Field(
        default=None,
        description="UTC timestamp when user data was most recently ingested",
    )
    models_uploaded_at: Optional[datetime] = Field(
        default=None,
        description="UTC timestamp when model data was most recently ingested",
    )
    first_chat_day: Optional[date] = Field(
        default=None,
        description="Date of the earliest chat/message in the current dataset",
    )
    last_chat_day: Optional[date] = Field(
        default=None,
        description="Date of the latest chat/message in the current dataset",
    )
    chat_count: int = Field(..., description="Number of chat records currently available")
    user_count: int = Field(..., description="Number of user records currently available")
    model_count: int = Field(..., description="Number of model records currently available")
    auth_user_count: int = Field(
        ..., description="Number of application login users configured"
    )


class DatasetMeta(BaseModel):
    """Metadata describing the currently loaded dataset.

    Attributes:
        dataset_id: Synthetic identifier that changes when data updates.
        source: Human-readable description of the dataset origin.
        last_updated: Last modification timestamp for the dataset.
        chat_count: Number of chats currently stored.
        message_count: Number of messages currently stored.
        user_count: Number of user records currently stored.
        app_metadata: Aggregate analytics metadata for the frontend.
    """

    dataset_id: str = Field(..., description="Opaque identifier that changes when data updates")
    source: str = Field(..., description="Human-friendly description of the data source")
    last_updated: datetime = Field(..., description="UTC timestamp of last modification")
    chat_count: int = Field(..., description="Number of chats available")
    message_count: int = Field(..., description="Number of messages available")
    user_count: int = Field(..., description="Number of user records available")
    model_count: int = Field(..., description="Number of model records available")
    app_metadata: Optional[AppMetadata] = Field(
        default=None,
        description="Aggregated metadata persisted to app.json for frontend display",
    )


class IngestLogEntry(BaseModel):
    """Audit record describing dataset ingestion actions."""

    id: int = Field(..., description="Primary key for the ingest log entry")
    operation: str = Field(..., description="Identifier for the ingest operation that ran")
    source: Optional[str] = Field(default=None, description="Optional source label provided by the caller")
    record_count: int = Field(..., description="Number of records processed during the operation")
    details: Dict[str, Any] = Field(default_factory=dict, description="Structured metadata captured for the run")
    created_at: datetime = Field(..., description="Timestamp when the log entry was created")
    updated_at: datetime = Field(..., description="Timestamp when the log entry was last updated")
    started_at: Optional[datetime] = Field(default=None, description="Optional start time for long running jobs")
    finished_at: Optional[datetime] = Field(default=None, description="Optional end time for long running jobs")
    notes: Optional[str] = Field(default=None, description="Additional notes captured during ingestion")


class AuthUserPublic(BaseModel):
    """Public representation of an authenticated user account."""

    id: str = Field(..., description="Canonical identifier for the user")
    username: str = Field(..., description="Username/email for authentication")
    email: str = Field(..., description="Email address, matches the username")
    name: str = Field(..., description="Display name for the authenticated user")


class AuthStatus(BaseModel):
    """Indicates whether any authentication users exist."""

    has_users: bool = Field(..., description="True if at least one auth user exists")


class AuthLoginRequest(BaseModel):
    """Login request payload."""

    username: str = Field(..., description="Username/email used to authenticate")
    password: str = Field(..., description="Plain text password to verify")


class AuthUserCreate(BaseModel):
    """Payload for creating the initial auth user."""

    username: str = Field(..., description="Username/email for the new account")
    password: str = Field(..., description="Plain text password for the new account")
    name: Optional[str] = Field(
        default=None,
        description="Optional human-friendly display name; defaults to the username",
    )


class AuthLoginResponse(BaseModel):
    """Login response payload returned to the frontend."""

    access_token: str = Field(..., description="Opaque token representing the session")
    token_type: Literal["bearer"] = Field(
        ..., description="Token type (always 'bearer' for compatibility)"
    )
    user: AuthUserPublic = Field(..., description="Public user details for the session")


class DatasetSyncStats(BaseModel):
    """Structured summary of a dataset sync operation."""

    mode: Literal["full", "incremental", "noop"] = Field(
        ...,
        description="Indicates whether the sync replaced all data, appended to existing data, or found nothing new.",
    )
    source_matched: bool = Field(
        ..., description="True when the submitted hostname matches the current dataset source."
    )
    submitted_hostname: str = Field(
        ..., description="Hostname submitted by the user for the sync request."
    )
    normalized_hostname: str = Field(
        ..., description="Normalized hostname used internally for Open WebUI requests."
    )
    source_display: str = Field(
        ..., description="Human-readable dataset source after the sync completes."
    )
    new_chats: int = Field(..., description="Number of newly appended chats.")
    new_messages: int = Field(..., description="Number of newly appended messages.")
    new_users: int = Field(..., description="Number of newly appended users.")
    new_models: int = Field(..., description="Number of newly appended models.")
    models_changed: bool = Field(
        ..., description="True when existing model records were updated during the sync."
    )
    summarizer_enqueued: bool = Field(
        ..., description="True when the summarizer was queued for the sync."
    )
    total_chats: int = Field(..., description="Total number of chats after the sync.")
    total_messages: int = Field(
        ..., description="Total number of messages after the sync."
    )
    total_users: int = Field(..., description="Total number of users after the sync.")
    total_models: int = Field(..., description="Total number of models after the sync.")
    queued_chat_ids: Optional[List[str]] = Field(
        default=None,
        description="Identifiers of chats queued for summarization (if partial job scheduled).",
    )


class UploadResponse(BaseModel):
    """Response payload returned after successful uploads."""

    detail: str = Field(..., description="Human readable status message")
    dataset: DatasetMeta = Field(..., description="Dataset metadata after the upload finishes")
    stats: Optional[DatasetSyncStats] = Field(
        default=None,
        description="Optional sync statistics returned by direct-connect operations.",
    )


class OpenWebUISyncRequest(BaseModel):
    """Payload required to sync data directly from an Open WebUI instance."""

    hostname: str = Field(..., description="Base URL of the Open WebUI instance")
    api_key: Optional[str] = Field(
        default=None, description="Bearer token used to authenticate with Open WebUI"
    )
    mode: Optional[Literal["full", "incremental"]] = Field(
        default=None,
        description="Sync mode: 'full' replaces all data, 'incremental' appends new data. Defaults to incremental if data exists.",
    )


class SyncStatusResponse(BaseModel):
    """Current sync status and watermark information."""

    last_sync_at: Optional[datetime] = Field(
        default=None,
        description="ISO timestamp of the last successful sync operation.",
    )
    last_watermark: Optional[str] = Field(
        default=None,
        description="Watermark of the last sync (e.g., max updated_at timestamp).",
    )
    has_data: bool = Field(
        ...,
        description="True if dataset currently contains data.",
    )
    recommended_mode: Literal["full", "incremental"] = Field(
        ...,
        description="Recommended sync mode based on current state.",
    )
    is_stale: bool = Field(
        ...,
        description="True if data is stale (last sync beyond staleness threshold).",
    )
    staleness_threshold_hours: int = Field(
        ...,
        description="Configured staleness threshold in hours.",
    )
    local_counts: Optional[Dict[str, int]] = Field(
        default=None,
        description="Local data counts (chats, messages, users, models).",
    )


class ProcessLogEvent(BaseModel):
    """Structured log event emitted during processing operations."""

    timestamp: datetime = Field(..., description="When the event occurred (UTC)")
    level: Literal["debug", "info", "warning", "error"] = Field(..., description="Log severity level")
    job_id: Optional[str] = Field(default=None, description="Unique job identifier for filtering")
    phase: Literal["connect", "fetch", "persist", "summarize", "done", "error"] = Field(
        ..., description="Current phase of the operation"
    )
    message: str = Field(..., description="Human-readable log message")
    details: Optional[Dict[str, Any]] = Field(default=None, description="Additional structured details")


class ProcessLogsResponse(BaseModel):
    """Response containing recent process log events."""

    logs: List[ProcessLogEvent] = Field(..., description="List of log events")
    total: int = Field(..., description="Total number of events in buffer")


class SyncSchedulerConfig(BaseModel):
    """Configuration for automatic periodic sync scheduler."""

    enabled: bool = Field(
        ...,
        description="Whether the periodic sync scheduler is enabled.",
    )
    interval_minutes: int = Field(
        ...,
        description="Interval between automatic syncs in minutes.",
        ge=5,  # Minimum 5 minutes
        le=1440,  # Maximum 24 hours
    )
    last_run_at: Optional[datetime] = Field(
        default=None,
        description="Timestamp of the last automatic sync run.",
    )
    next_run_at: Optional[datetime] = Field(
        default=None,
        description="Timestamp when the next automatic sync is scheduled.",
    )


class SyncSchedulerUpdate(BaseModel):
    """Request to update sync scheduler configuration."""

    enabled: Optional[bool] = Field(
        default=None,
        description="Enable or disable the scheduler.",
    )
    interval_minutes: Optional[int] = Field(
        default=None,
        description="Update the sync interval in minutes (5-1440).",
        ge=5,
        le=1440,
    )


class AdminDirectConnectSettings(BaseModel):
    """Admin-configurable defaults for Open WebUI Direct Connect."""

    host: str = Field(
        ...,
        description="Effective base URL used for Direct Connect operations.",
    )
    api_key: str = Field(
        ...,
        description="Effective API key used for Direct Connect operations.",
    )
    database_host: str = Field(
        default="",
        description="Base URL stored in the database (if available).",
    )
    database_api_key: str = Field(
        default="",
        description="API key stored in the database (if available).",
    )
    host_source: Literal["database", "environment", "default"] = Field(
        ...,
        description="Origin for the host value (database, environment, or built-in default).",
    )
    api_key_source: Literal["database", "environment", "empty"] = Field(
        ...,
        description="Origin for the API key value (database, environment, or empty when unset).",
    )


class AdminDirectConnectSettingsUpdate(BaseModel):
    """Payload allowing admins to update Direct Connect defaults."""

    host: Optional[str] = Field(
        default=None,
        description="New base URL for Open WebUI Direct Connect; omit to keep existing value.",
    )
    api_key: Optional[str] = Field(
        default=None,
        description="New API key for Open WebUI Direct Connect; omit to keep existing value.",
    )


class OpenWebUIHealthTestRequest(BaseModel):
    """Request payload for testing OpenWebUI connection."""

    host: Optional[str] = Field(
        default=None,
        description="OpenWebUI host URL to test; if omitted, uses stored setting.",
    )
    api_key: Optional[str] = Field(
        default=None,
        description="API key to test; if omitted, uses stored setting.",
    )


class GenAIMessage(BaseModel):
    """Chat message payload exchanged with Ollama."""

    role: Literal["system", "user", "assistant"] = Field(
        ..., description="Speaker role for the chat turn"
    )
    content: str = Field(..., description="Content of the chat message")


class GenAISummarizeRequest(BaseModel):
    """Request payload for summary generation."""

    context: str = Field(..., description="Conversation or document snippet to summarize")
    model: Optional[str] = Field(
        default=None, description="Override the default summary model identifier"
    )
    max_chars: Optional[int] = Field(
        default=None, description="Optional character limit for the returned summary"
    )
    temperature: Optional[float] = Field(
        default=None, description="Optional temperature override for the summary model"
    )


class GenAISummarizeResponse(BaseModel):
    """Response payload for summary generation."""

    summary: str = Field(..., description="Generated single-line summary text")
    model: str = Field(..., description="Model identifier used to create the summary")


class GenAIGenerateRequest(BaseModel):
    """Generic text generation request payload."""

    prompt: str = Field(..., description="Prompt provided to the model")
    model: Optional[str] = Field(
        default=None, description="Override the default model identifier"
    )
    system: Optional[str] = Field(
        default=None, description="Optional system prompt to prepend"
    )
    options: Dict[str, Any] = Field(
        default_factory=dict,
        description="Low-level Ollama generation options (e.g., temperature, num_predict)",
    )


class GenAIGenerateResponse(BaseModel):
    """Generic text generation response payload."""

    text: str = Field(..., description="Generated text returned by the model")
    model: str = Field(..., description="Model identifier used for the response")
    raw: Dict[str, Any] = Field(
        default_factory=dict, description="Raw response payload returned by Ollama"
    )


class GenAIChatRequest(BaseModel):
    """Multi-turn chat generation request payload."""

    messages: List[GenAIMessage] = Field(..., description="Ordered list of chat messages")
    model: Optional[str] = Field(
        default=None, description="Override the default chat model identifier"
    )
    options: Dict[str, Any] = Field(
        default_factory=dict,
        description="Low-level Ollama chat options (e.g., temperature, top_p)",
    )


class GenAIChatResponse(BaseModel):
    """Multi-turn chat generation response payload."""

    message: GenAIMessage = Field(..., description="Assistant message returned by the model")
    model: str = Field(..., description="Model identifier used for the response")
    raw: Dict[str, Any] = Field(
        default_factory=dict, description="Raw response payload returned by Ollama"
    )


class GenAIEmbedRequest(BaseModel):
    """Embedding generation request payload."""

    inputs: List[str] = Field(..., description="Collection of strings to embed")
    model: Optional[str] = Field(
        default=None, description="Override the default embedding model identifier"
    )


class GenAIEmbedResponse(BaseModel):
    """Embedding generation response payload."""

    embeddings: List[List[float]] = Field(
        ..., description="Embeddings returned by the Ollama service"
    )
    model: str = Field(..., description="Model identifier used for the embeddings")
    raw: Dict[str, Any] = Field(
        default_factory=dict, description="Raw response payload returned by Ollama"
    )
